<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Car Types</title>
  <link rel="stylesheet" href="style.css" />

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jimp/0.22.10/jimp.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
  <main class="container">
    <section class="upload-section">
      <h1>Car Types</h1>
      <p>Select an image to see if it's a Pick-Up, Sedan, or SUV.</p>
      <p>Warning: Do not cropped images, it will cause errors. Only load images that are related to Pick-Up, Sedan, and SUV.</p>
      <input type="file" name="Image" onchange="inputChanged(event)" autocomplete="off" />
    </section>

    <section class="status-section">
      <p><strong>Status:</strong> <span id="status-output">Loading model...</span></p>
    </section>

    <section class="output-section">
      <h2>Model Output</h2>
      <div id="model-output"></div>
    </section>
  </main>

  <script>
    const statusDict = ["Waiting for file", "Loading file", "Performing inference", "Inference complete"];
    const modelClasses = ['Pick-Up', 'Sedan', 'SUV'];
    const statusOutput = document.getElementById("status-output");

    async function getImageTensorFromPath(path, dims = [1, 3, 64, 64]) {
      const image = await loadImagefromPath(path, dims[2], dims[3]);
      return imageDataToTensor(image, dims);
    }

    async function loadImagefromPath(path, width = 64, height = 64) {
            // Use Jimp to load the image and resize it.
            var imageData = await Jimp.read(path).then((imageBuffer) => {
                return imageBuffer.cover(width, height);
            });

            return imageData;
        }

    function imageDataToTensor(image, dims) {
          const imageBufferData = image.bitmap.data;
          const [batch, channels, height, width] = dims;
        
          const float32Data = new Float32Array(channels * height * width);
        
          for (let i = 0, px = 0; i < imageBufferData.length; i += 4, px++) {
            const r = (imageBufferData[i] / 255 - 0.5) / 0.5;
            const g = (imageBufferData[i + 1] / 255 - 0.5) / 0.5;
            const b = (imageBufferData[i + 2] / 255 - 0.5) / 0.5;
        
            // Channel-first format: [C, H, W]
            float32Data[0 * width * height + px] = r; // Red channel
            float32Data[1 * width * height + px] = g; // Green channel
            float32Data[2 * width * height + px] = b; // Blue channel
          }
        
          const inputTensor = new ort.Tensor("float32", float32Data, dims);
          console.log(inputTensor);
          return inputTensor;
        }
      

        const isTypedArray = (function() {
            const TypedArray = Object.getPrototypeOf(Uint8Array);
            return (obj) => obj instanceof TypedArray;
        })();

    function sortedClasses(classProbabilities) {
      const probs = Array.from(classProbabilities);
      return probs.map((prob, i) => [prob, i])
        .sort((a, b) => b[0] - a[0])
        .map(([prob, index]) => ({
          index,
          name: modelClasses[index],
          probability: prob
        }));
    }

    function softmax(arr) {
      const max = Math.max(...arr);
      const exps = arr.map(x => Math.exp(x - max));
      const sum = exps.reduce((a, b) => a + b);
      return exps.map(e => e / sum);
    }

    async function inference(path) {
      const session = await ort.InferenceSession.create('car_body_model.onnx');
      const imageTensor = await getImageTensorFromPath(path);
      statusOutput.textContent = statusDict[2];
      const results = await session.run({ input: imageTensor });
      return softmax(Array.from(results.output.data));
    }

    async function inputChanged(event) {
      statusOutput.textContent = statusDict[1];
      const result = await inference(URL.createObjectURL(event.target.files[0]));
      const classes = sortedClasses(result);
      const outputDiv = document.getElementById("model-output");

      outputDiv.innerHTML = "";
      classes.forEach((entry, index) => {
        const resultEl = document.createElement("div");
        resultEl.className = index === 0 ? "result top" : "result";
        resultEl.innerHTML = `
          <strong>${entry.name}</strong>
          <ul>
            <li>Class ID: ${entry.index}</li>
            <li>Probability: ${entry.probability.toFixed(4)}</li>
          </ul>`;
        outputDiv.appendChild(resultEl);
      });
      statusOutput.textContent = statusDict[3];
    }

    statusOutput.textContent = statusDict[0];
  </script>
</body>
</html>

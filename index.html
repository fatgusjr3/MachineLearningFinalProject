<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Car Types</title>
  <link rel="stylesheet" href="style.css" />

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jimp/0.22.10/jimp.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
  <main class="container">
    <section class="upload-section">
      <h1>Car Types</h1>
      <p>Select an image to see if it's a Pick-Up, Sedan, or SUV.</p>
      <p>Warning: Do not cropped images, it will cause errors. Only load images that are related to Pick-Up, Sedan, and SUV.</p>
      <input type="file" name="Image" onchange="inputChanged(event)" autocomplete="off" />
    </section>

    <section class="status-section">
      <p><strong>Status:</strong> <span id="status-output">Loading model...</span></p>
    </section>

    <section class="output-section">
      <h2>Model Output</h2>
      <div id="model-output"></div>
    </section>
  </main>

  <script>
    const statusDict = ["Waiting for file", "Loading file", "Performing inference", "Inference complete"];
    const modelClasses = ['Pick-Up', 'Sedan', 'SUV'];
    const statusOutput = document.getElementById("status-output");

    async function getImageTensorFromPath(path, dims = [1, 3, 64, 64]) {
      const image = await loadImagefromPath(path, dims[2], dims[3]);
      return imageDataToTensor(image, dims);
    }

    function imageDataToTensor(image, dims) {
      const data = image.bitmap.data;
      const r = [], g = [], b = [];

      for (let i = 0; i < data.length; i += 4) {
        r.push(data[i]);
        g.push(data[i + 1]);
        b.push(data[i + 2]);
      }

        // Example mean and std for each channel (replace with your actual values)
        const mean = [0.4183, 0.4093, 0.4163];
        const std = [0.2685, 0.2648, 0.2692];

        // 3. Normalize each channel separately
        const normRed = r.map(v => ((v / 255.0) - mean[0]) / std[0]);
        const normGreen = g.map(v => ((v / 255.0) - mean[1]) / std[1]);
        const normBlue = b.map(v => ((v / 255.0) - mean[2]) / std[2]);

        // Then concatenate in channel-first order: [3, 64, 64]
        const transposedData = normRed.concat(normGreen).concat(normBlue);

        // 4. Convert to Float32Array
        const float32Data = new Float32Array(transposedData.length);
        for (let i = 0; i < transposedData.length; i++) {
            float32Data[i] = transposedData[i];
        }

        // 5. Create the tensor
        const inputTensor = new ort.Tensor("float32", float32Data, dims);
        console.log(inputTensor);
        return inputTensor;
    }

    async function loadImagefromPath(path, width = 64, height = 64) {
      try {
        const image = await Jimp.read(path);
        image.cover(width, height);
        return image;
      } catch (err) {
        console.error("Error loading image:", err);
        statusoutput.textContent = "Error loading image file. Please try another image.";
        throw err;
      }
    }

    function sortedClasses(classProbabilities) {
      const probs = Array.from(classProbabilities);
      return probs.map((prob, i) => [prob, i])
        .sort((a, b) => b[0] - a[0])
        .map(([prob, index]) => ({
          index,
          name: modelClasses[index],
          probability: prob
        }));
    }

    function softmax(arr) {
      const max = Math.max(...arr);
      const exps = arr.map(x => Math.exp(x - max));
      const sum = exps.reduce((a, b) => a + b);
      return exps.map(e => e / sum);
    }

    async function inference(path) {
      const session = await ort.InferenceSession.create('car_body_model.onnx');
      const imageTensor = await getImageTensorFromPath(path);
      statusOutput.textContent = statusDict[2];
      const results = await session.run({ input: imageTensor });
      return softmax(Array.from(results.output.data));
    }

    async function inputChanged(event) {
      statusOutput.textContent = statusDict[1];
      const result = await inference(URL.createObjectURL(event.target.files[0]));
      const classes = sortedClasses(result);
      const outputDiv = document.getElementById("model-output");

      outputDiv.innerHTML = "";
      classes.forEach((entry, index) => {
        const resultEl = document.createElement("div");
        resultEl.className = index === 0 ? "result top" : "result";
        resultEl.innerHTML = `
          <strong>${entry.name}</strong>
          <ul>
            <li>Class ID: ${entry.index}</li>
            <li>Probability: ${entry.probability.toFixed(4)}</li>
          </ul>`;
        outputDiv.appendChild(resultEl);
      });
      statusOutput.textContent = statusDict[3];
    }

    statusOutput.textContent = statusDict[0];
  </script>
</body>
</html>
